{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"trainClassification.csv\")\n",
    "df_test=pd.read_csv(\"testClassification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_train.drop(['RUL','label'],axis=1)\n",
    "test=df_test.drop(['RUL','label'],axis=1)\n",
    "df=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 27)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicleId</th>\n",
       "      <th>days</th>\n",
       "      <th>ecoMode</th>\n",
       "      <th>cityMode</th>\n",
       "      <th>sportMode</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>label_bc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.0</td>\n",
       "      <td>2.063100e+04</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>2.063100e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>2.063100e+04</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.0</td>\n",
       "      <td>20631.0</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.506568</td>\n",
       "      <td>108.807862</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>642.680934</td>\n",
       "      <td>1590.523119</td>\n",
       "      <td>1408.933782</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.096152</td>\n",
       "      <td>8143.752722</td>\n",
       "      <td>8.442146</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>393.210654</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.816271</td>\n",
       "      <td>23.289705</td>\n",
       "      <td>0.150259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.227633</td>\n",
       "      <td>68.880990</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.537152e-11</td>\n",
       "      <td>0.500053</td>\n",
       "      <td>6.131150</td>\n",
       "      <td>9.000605</td>\n",
       "      <td>3.394700e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071919</td>\n",
       "      <td>19.076176</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>1.556432e-14</td>\n",
       "      <td>1.548763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180746</td>\n",
       "      <td>0.108251</td>\n",
       "      <td>0.357334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008700</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>641.210000</td>\n",
       "      <td>1571.040000</td>\n",
       "      <td>1382.250000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.880000</td>\n",
       "      <td>8099.940000</td>\n",
       "      <td>8.324900</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.140000</td>\n",
       "      <td>22.894200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>642.325000</td>\n",
       "      <td>1586.260000</td>\n",
       "      <td>1402.360000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.040000</td>\n",
       "      <td>8133.245000</td>\n",
       "      <td>8.414900</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.700000</td>\n",
       "      <td>23.221800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>642.640000</td>\n",
       "      <td>1590.100000</td>\n",
       "      <td>1408.040000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.090000</td>\n",
       "      <td>8140.540000</td>\n",
       "      <td>8.438900</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.830000</td>\n",
       "      <td>23.297900</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>1594.380000</td>\n",
       "      <td>1414.555000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.140000</td>\n",
       "      <td>8148.310000</td>\n",
       "      <td>8.465600</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.950000</td>\n",
       "      <td>23.366800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>644.530000</td>\n",
       "      <td>1616.910000</td>\n",
       "      <td>1441.490000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.560000</td>\n",
       "      <td>8293.720000</td>\n",
       "      <td>8.584800</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.430000</td>\n",
       "      <td>23.618400</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          vehicleId          days       ecoMode      cityMode  sportMode  \\\n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000    20631.0   \n",
       "mean      51.506568    108.807862     -0.000009      0.000002      100.0   \n",
       "std       29.227633     68.880990      0.002187      0.000293        0.0   \n",
       "min        1.000000      1.000000     -0.008700     -0.000600      100.0   \n",
       "25%       26.000000     52.000000     -0.001500     -0.000200      100.0   \n",
       "50%       52.000000    104.000000      0.000000      0.000000      100.0   \n",
       "75%       77.000000    156.000000      0.001500      0.000300      100.0   \n",
       "max      100.000000    362.000000      0.008700      0.000600      100.0   \n",
       "\n",
       "                 s1            s2            s3            s4            s5  \\\n",
       "count  2.063100e+04  20631.000000  20631.000000  20631.000000  2.063100e+04   \n",
       "mean   5.186700e+02    642.680934   1590.523119   1408.933782  1.462000e+01   \n",
       "std    6.537152e-11      0.500053      6.131150      9.000605  3.394700e-12   \n",
       "min    5.186700e+02    641.210000   1571.040000   1382.250000  1.462000e+01   \n",
       "25%    5.186700e+02    642.325000   1586.260000   1402.360000  1.462000e+01   \n",
       "50%    5.186700e+02    642.640000   1590.100000   1408.040000  1.462000e+01   \n",
       "75%    5.186700e+02    643.000000   1594.380000   1414.555000  1.462000e+01   \n",
       "max    5.186700e+02    644.530000   1616.910000   1441.490000  1.462000e+01   \n",
       "\n",
       "       ...           s13           s14           s15           s16  \\\n",
       "count  ...  20631.000000  20631.000000  20631.000000  2.063100e+04   \n",
       "mean   ...   2388.096152   8143.752722      8.442146  3.000000e-02   \n",
       "std    ...      0.071919     19.076176      0.037505  1.556432e-14   \n",
       "min    ...   2387.880000   8099.940000      8.324900  3.000000e-02   \n",
       "25%    ...   2388.040000   8133.245000      8.414900  3.000000e-02   \n",
       "50%    ...   2388.090000   8140.540000      8.438900  3.000000e-02   \n",
       "75%    ...   2388.140000   8148.310000      8.465600  3.000000e-02   \n",
       "max    ...   2388.560000   8293.720000      8.584800  3.000000e-02   \n",
       "\n",
       "                s17      s18      s19           s20           s21  \\\n",
       "count  20631.000000  20631.0  20631.0  20631.000000  20631.000000   \n",
       "mean     393.210654   2388.0    100.0     38.816271     23.289705   \n",
       "std        1.548763      0.0      0.0      0.180746      0.108251   \n",
       "min      388.000000   2388.0    100.0     38.140000     22.894200   \n",
       "25%      392.000000   2388.0    100.0     38.700000     23.221800   \n",
       "50%      393.000000   2388.0    100.0     38.830000     23.297900   \n",
       "75%      394.000000   2388.0    100.0     38.950000     23.366800   \n",
       "max      400.000000   2388.0    100.0     39.430000     23.618400   \n",
       "\n",
       "           label_bc  \n",
       "count  20631.000000  \n",
       "mean       0.150259  \n",
       "std        0.357334  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20631.000000\n",
       "mean         0.150259\n",
       "std          0.357334\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: label_bc, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label_bc'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### only 15% positive(1) and 85% negative(0) , so it is unbalaced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean     206.310000\n",
       "std       46.342749\n",
       "min      128.000000\n",
       "25%      177.000000\n",
       "50%      199.000000\n",
       "75%      229.250000\n",
       "max      362.000000\n",
       "Name: days, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['RUL']==0].days.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicleId</th>\n",
       "      <th>days</th>\n",
       "      <th>ecoMode</th>\n",
       "      <th>cityMode</th>\n",
       "      <th>sportMode</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>label_bc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20626</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.49</td>\n",
       "      <td>1597.98</td>\n",
       "      <td>1428.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.60</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.49</td>\n",
       "      <td>22.9735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1604.50</td>\n",
       "      <td>1433.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8136.50</td>\n",
       "      <td>8.5139</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.1594</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1602.46</td>\n",
       "      <td>1428.18</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>8141.05</td>\n",
       "      <td>8.5646</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.44</td>\n",
       "      <td>22.9333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.23</td>\n",
       "      <td>1605.26</td>\n",
       "      <td>1426.53</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8139.29</td>\n",
       "      <td>8.5389</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.29</td>\n",
       "      <td>23.0640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.85</td>\n",
       "      <td>1600.38</td>\n",
       "      <td>1432.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.33</td>\n",
       "      <td>8.5036</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20631 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       vehicleId  days  ecoMode  cityMode  sportMode      s1      s2       s3  \\\n",
       "0              1     1  -0.0007   -0.0004        100  518.67  641.82  1589.70   \n",
       "1              1     2   0.0019   -0.0003        100  518.67  642.15  1591.82   \n",
       "2              1     3  -0.0043    0.0003        100  518.67  642.35  1587.99   \n",
       "3              1     4   0.0007    0.0000        100  518.67  642.35  1582.79   \n",
       "4              1     5  -0.0019   -0.0002        100  518.67  642.37  1582.85   \n",
       "...          ...   ...      ...       ...        ...     ...     ...      ...   \n",
       "20626        100   196  -0.0004   -0.0003        100  518.67  643.49  1597.98   \n",
       "20627        100   197  -0.0016   -0.0005        100  518.67  643.54  1604.50   \n",
       "20628        100   198   0.0004    0.0000        100  518.67  643.42  1602.46   \n",
       "20629        100   199  -0.0011    0.0003        100  518.67  643.23  1605.26   \n",
       "20630        100   200  -0.0032   -0.0005        100  518.67  643.85  1600.38   \n",
       "\n",
       "            s4     s5  ...      s13      s14     s15   s16  s17   s18  s19  \\\n",
       "0      1400.60  14.62  ...  2388.02  8138.62  8.4195  0.03  392  2388  100   \n",
       "1      1403.14  14.62  ...  2388.07  8131.49  8.4318  0.03  392  2388  100   \n",
       "2      1404.20  14.62  ...  2388.03  8133.23  8.4178  0.03  390  2388  100   \n",
       "3      1401.87  14.62  ...  2388.08  8133.83  8.3682  0.03  392  2388  100   \n",
       "4      1406.22  14.62  ...  2388.04  8133.80  8.4294  0.03  393  2388  100   \n",
       "...        ...    ...  ...      ...      ...     ...   ...  ...   ...  ...   \n",
       "20626  1428.63  14.62  ...  2388.26  8137.60  8.4956  0.03  397  2388  100   \n",
       "20627  1433.58  14.62  ...  2388.22  8136.50  8.5139  0.03  395  2388  100   \n",
       "20628  1428.18  14.62  ...  2388.24  8141.05  8.5646  0.03  398  2388  100   \n",
       "20629  1426.53  14.62  ...  2388.23  8139.29  8.5389  0.03  395  2388  100   \n",
       "20630  1432.14  14.62  ...  2388.26  8137.33  8.5036  0.03  396  2388  100   \n",
       "\n",
       "         s20      s21  label_bc  \n",
       "0      39.06  23.4190         0  \n",
       "1      39.00  23.4236         0  \n",
       "2      38.95  23.3442         0  \n",
       "3      38.88  23.3739         0  \n",
       "4      38.90  23.4044         0  \n",
       "...      ...      ...       ...  \n",
       "20626  38.49  22.9735         1  \n",
       "20627  38.30  23.1594         1  \n",
       "20628  38.44  22.9333         1  \n",
       "20629  38.29  23.0640         1  \n",
       "20630  38.37  23.0522         1  \n",
       "\n",
       "[20631 rows x 27 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3100"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_bc'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20631"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_bc'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    17531\n",
      "1     3100\n",
      "Name: label_bc, dtype: int64\n",
      "\n",
      "Negaitve samples =  15%\n",
      "\n",
      "Posiitve samples =  85%\n"
     ]
    }
   ],
   "source": [
    "print(df['label_bc'].value_counts())\n",
    "print('\\nNegaitve samples =  {0:.0%}'.format(df['label_bc'].value_counts()[1]/df['label_bc'].count()))\n",
    "print('\\nPosiitve samples =  {0:.0%}'.format(df['label_bc'].value_counts()[0]/df['label_bc'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15025931850128446"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_bc'].value_counts()[1]/df['label_bc'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vehicleId   -1.448230e-02\n",
       "days         5.036790e-01\n",
       "ecoMode      1.049943e-02\n",
       "cityMode     9.402176e-03\n",
       "sportMode             NaN\n",
       "s1           8.198058e-16\n",
       "s2           5.814040e-01\n",
       "s3           5.618920e-01\n",
       "s4           6.484064e-01\n",
       "s5           2.220435e-15\n",
       "s6           5.957942e-02\n",
       "s7          -6.255919e-01\n",
       "s8           5.429101e-01\n",
       "s9           4.195389e-01\n",
       "s10         -5.044491e-16\n",
       "s11          6.656552e-01\n",
       "s12         -6.401737e-01\n",
       "s13          5.399146e-01\n",
       "s14          3.410628e-01\n",
       "s15          6.187318e-01\n",
       "s16         -3.382962e-16\n",
       "s17          5.830666e-01\n",
       "s18                   NaN\n",
       "s19                   NaN\n",
       "s20         -5.999121e-01\n",
       "s21         -6.064804e-01\n",
       "label_bc     1.000000e+00\n",
       "Name: label_bc, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_relation=train.corr()[\"label_bc\"]\n",
    "co_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_bc     1.000000e+00\n",
       "s11          6.656552e-01\n",
       "s4           6.484064e-01\n",
       "s12          6.401737e-01\n",
       "s7           6.255919e-01\n",
       "s15          6.187318e-01\n",
       "s21          6.064804e-01\n",
       "s20          5.999121e-01\n",
       "s17          5.830666e-01\n",
       "s2           5.814040e-01\n",
       "s3           5.618920e-01\n",
       "s8           5.429101e-01\n",
       "s13          5.399146e-01\n",
       "days         5.036790e-01\n",
       "s9           4.195389e-01\n",
       "s14          3.410628e-01\n",
       "s6           5.957942e-02\n",
       "vehicleId    1.448230e-02\n",
       "ecoMode      1.049943e-02\n",
       "cityMode     9.402176e-03\n",
       "s5           2.220435e-15\n",
       "s1           8.198058e-16\n",
       "s10          5.044491e-16\n",
       "s16          3.382962e-16\n",
       "sportMode             NaN\n",
       "s18                   NaN\n",
       "s19                   NaN\n",
       "Name: label_bc, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_relation.abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['s11', 's4', 's12', 's7', 's15', 's21', 's20', 's17', 's2', 's3', 's8',\n",
       "       's13', 'days', 's9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corelated=co_relation.abs().sort_values(ascending=False)[1:].head(14).index\n",
    "corelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['s14', 's6', 'vehicleId', 'ecoMode', 'cityMode', 's5', 's1', 's10',\n",
       "       's16', 'sportMode', 's18', 's19'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_corelated=co_relation.abs().sort_values(ascending=False)[15:].index\n",
    "not_corelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=train.drop('label_bc',axis=1),train[\"label_bc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,y_test=test.drop('label_bc',axis=1),test[\"label_bc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "- using  SelectFromModel(Lasso(alpha=0.005, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Lasso(alpha=0.005, random_state=0))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a suitable alpha (equivalent of penalty).\n",
    "# The bigger the alpha the less features that will be selected.\n",
    "# 0.005 due his indrustry expericence\n",
    "\n",
    "feature_sel_model = SelectFromModel(Lasso(alpha=0.005, random_state=0)) # remember to set the seed, the random state in this function\n",
    "feature_sel_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False, False,  True,  True,  True,\n",
       "       False, False,  True, False,  True, False, False,  True, False,\n",
       "        True, False, False,  True, False, False, False, False])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sel_model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vehicleId', 'days', 's2', 's3', 's4', 's7', 's9', 's12', 's14', 's17'], dtype='object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's print the number of total and selected features\n",
    "\n",
    "# this is how we can make a list of the selected features\n",
    "selected_feat = cols[(feature_sel_model.get_support())]\n",
    "selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['s11', 's4', 's12', 's7', 's15', 's21', 's20', 's17', 's2', 's3', 's8',\n",
      "       's13', 'days', 's9'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['s11', 's13', 's15', 's20', 's21', 's8'], dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(corelated)\n",
    "corelated.difference(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stat\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_data(df,feature):\n",
    "    print(feature)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    df[feature].hist()\n",
    "    plt.subplot(1,2,2)\n",
    "    stat.probplot(df[feature],dist='norm',plot=pylab)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def distributions(df,feature):\n",
    "    df[feature+'_log']=np.log(df[feature])\n",
    "    plot_data(df,feature+'_log')\n",
    "    df[feature+'_log1p']=np.log1p(df[feature])\n",
    "    plot_data(df,feature+'_log1p')\n",
    "    df[feature+'_reciprocal']=1/df[feature]\n",
    "    plot_data(df,feature+'_reciprocal')\n",
    "    df[feature+'_sqaure']=df[feature]**(1/2)\n",
    "    plot_data(df,feature+'_sqaure')\n",
    "    df[feature+'exponential']=df[feature]**(1/1.2)\n",
    "    plot_data(df,feature+'exponential')\n",
    "    df[feature+'_boxcox'],parameters=stat.boxcox(train[feature])\n",
    "    print(parameters)\n",
    "    plot_data(df,feature+'_boxcox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.89\n",
      "\n",
      "confusion_matrix \n",
      "[[74 10]\n",
      " [ 1 15]]\n",
      "\n",
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93        84\n",
      "           1       0.60      0.94      0.73        16\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.79      0.91      0.83       100\n",
      "weighted avg       0.92      0.89      0.90       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "y_pred=logreg.predict(X_test)\n",
    "train_pred=logreg.predict(X_train)\n",
    "def metrices(pred,y_test):\n",
    "    print(\"accuracy_score {}\".format(accuracy_score(pred,y_test)))\n",
    "    print(\"\\nconfusion_matrix \\n{}\".format(confusion_matrix(pred,y_test)))\n",
    "    print(\"\\nclassification_report {}\".format(classification_report(pred,y_test)))\n",
    "\n",
    "metrices(y_pred,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93        84\n",
      "           1       0.60      0.94      0.73        16\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.79      0.91      0.83       100\n",
      "weighted avg       0.92      0.89      0.90       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        75\n",
      "           1       0.94      0.60      0.73        25\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.91      0.79      0.83       100\n",
      "weighted avg       0.90      0.89      0.88       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74, 10],\n",
       "       [ 1, 15]], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[74,  1],\n",
       "       [10, 15]], dtype=int64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    75\n",
       "1    25\n",
       "Name: label_bc, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['label_bc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.94154427802821\n",
      "\n",
      "confusion_matrix \n",
      "[[17050   725]\n",
      " [  481  2375]]\n",
      "\n",
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     17775\n",
      "           1       0.77      0.83      0.80      2856\n",
      "\n",
      "    accuracy                           0.94     20631\n",
      "   macro avg       0.87      0.90      0.88     20631\n",
      "weighted avg       0.94      0.94      0.94     20631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrices(train_pred,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation for logistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "score=cross_val_score(logreg,X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95445736, 0.95104217, 0.93504605, 0.94716432, 0.95007271,\n",
       "       0.94716432, 0.92825982, 0.94328648, 0.94377121, 0.92971401])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9429978450138468"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classifier models\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression()))\n",
    "models.append(('Naive Bayes',GaussianNB()))\n",
    "models.append(('RandomForest', RandomForestClassifier()))\n",
    "models.append(('Decision Tree', DecisionTreeClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors = 5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression', LogisticRegression()),\n",
       " ('Naive Bayes', GaussianNB()),\n",
       " ('RandomForest', RandomForestClassifier()),\n",
       " ('Decision Tree', DecisionTreeClassifier()),\n",
       " ('KNN', KNeighborsClassifier())]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogisticRegression', 'Naive Bayes', 'RandomForest', 'Decision Tree', 'KNN']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[models[i][0] for i in range(len(models))]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier\n",
       "0  LogisticRegression\n",
       "1         Naive Bayes\n",
       "2        RandomForest\n",
       "3       Decision Tree\n",
       "4                 KNN"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1={\"Classifier\":[models[i][0] for i in range(len(models))]}\n",
    "result_df=pd.DataFrame(dict1)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier\n",
       "0  LogisticRegression\n",
       "1         Naive Bayes\n",
       "2        RandomForest\n",
       "3       Decision Tree\n",
       "4                 KNN"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 26)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_fitting(X_train,X_test,title):\n",
    "    accuracy=[]\n",
    "    score=[]\n",
    "    auc=[]\n",
    "    for name, model in models:\n",
    "        print(name)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions.\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "        #getting training accuracy\n",
    "\n",
    "        if name!='KNN':\n",
    "            from sklearn.metrics import accuracy_score\n",
    "            train_pred = model.predict(X_train)\n",
    "            print(\"training accuracy\")\n",
    "            print(accuracy_score(train_pred,y_train))\n",
    "\n",
    "        # ROC AUC\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        print(\"roc_auc_score \\n{}\" .format(roc_auc_score(predictions, y_test)))\n",
    "        \n",
    "        # Compute the error.\n",
    "        from sklearn.metrics import f1_score\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        print(\"\\n f1_score \\n\",f1_score(predictions, y_test))\n",
    "        print(\"\\n\",confusion_matrix(predictions, y_test))\n",
    "        print(\"\\n accuracy_score \\n\",accuracy_score(predictions,y_test))\n",
    "        \n",
    "        #ccollecting accuracy,f1_score,roc_auc_score\n",
    "        \n",
    "        accuracy.append(accuracy_score(predictions,y_test))\n",
    "        score.append(f1_score(predictions,y_test))\n",
    "        auc.append(roc_auc_score(predictions,y_test))\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "    result_df[title+\"_A\"]=accuracy\n",
    "    result_df[title+\"_f1\"]=score\n",
    "    result_df[title+\"_AUC\"]=auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy\n",
      "0.94154427802821\n",
      "roc_auc_score \n",
      "0.9092261904761905\n",
      "\n",
      " f1_score \n",
      " 0.7317073170731707\n",
      "\n",
      " [[74 10]\n",
      " [ 1 15]]\n",
      "\n",
      " accuracy_score \n",
      " 0.89\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "training accuracy\n",
      "0.9292327080606854\n",
      "roc_auc_score \n",
      "0.8968253968253967\n",
      "\n",
      " f1_score \n",
      " 0.8679245283018867\n",
      "\n",
      " [[70  2]\n",
      " [ 5 23]]\n",
      "\n",
      " accuracy_score \n",
      " 0.93\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.90625\n",
      "\n",
      " f1_score \n",
      " 0.7999999999999999\n",
      "\n",
      " [[73  7]\n",
      " [ 2 18]]\n",
      "\n",
      " accuracy_score \n",
      " 0.91\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.8933566433566434\n",
      "\n",
      " f1_score \n",
      " 0.8085106382978724\n",
      "\n",
      " [[72  6]\n",
      " [ 3 19]]\n",
      "\n",
      " accuracy_score \n",
      " 0.91\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "roc_auc_score \n",
      "0.8235294117647058\n",
      "\n",
      " f1_score \n",
      " 0.6\n",
      "\n",
      " [[72 13]\n",
      " [ 3 12]]\n",
      "\n",
      " accuracy_score \n",
      " 0.84\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_fitting(X_train,X_test,'direct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping non corelated fearture with dependence var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 14)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.drop(not_corelated,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy\n",
      "0.9420289855072463\n",
      "roc_auc_score \n",
      "0.9234417344173442\n",
      "\n",
      " f1_score \n",
      " 0.7906976744186047\n",
      "\n",
      " [[74  8]\n",
      " [ 1 17]]\n",
      "\n",
      " accuracy_score \n",
      " 0.91\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "training accuracy\n",
      "0.9294265910523\n",
      "roc_auc_score \n",
      "0.8824672170956775\n",
      "\n",
      " f1_score \n",
      " 0.851851851851852\n",
      "\n",
      " [[69  2]\n",
      " [ 6 23]]\n",
      "\n",
      " accuracy_score \n",
      " 0.92\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.9304743339831059\n",
      "\n",
      " f1_score \n",
      " 0.8181818181818181\n",
      "\n",
      " [[74  7]\n",
      " [ 1 18]]\n",
      "\n",
      " accuracy_score \n",
      " 0.92\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.9163713678242381\n",
      "\n",
      " f1_score \n",
      " 0.7619047619047621\n",
      "\n",
      " [[74  9]\n",
      " [ 1 16]]\n",
      "\n",
      " accuracy_score \n",
      " 0.9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "roc_auc_score \n",
      "0.8809355067328136\n",
      "\n",
      " f1_score \n",
      " 0.7142857142857143\n",
      "\n",
      " [[73 10]\n",
      " [ 2 15]]\n",
      "\n",
      " accuracy_score \n",
      " 0.88\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_fitting(X_train.drop(not_corelated,axis=1),X_test.drop(not_corelated,axis=1),'~low_corr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature selection \n",
    "- using SelectFromModel(Lasso(alpha=0.005, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 10)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[selected_feat].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy\n",
      "0.9461489990790558\n",
      "roc_auc_score \n",
      "0.9092261904761905\n",
      "\n",
      " f1_score \n",
      " 0.7317073170731707\n",
      "\n",
      " [[74 10]\n",
      " [ 1 15]]\n",
      "\n",
      " accuracy_score \n",
      " 0.89\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "training accuracy\n",
      "0.9319955406911928\n",
      "roc_auc_score \n",
      "0.9305477131564088\n",
      "\n",
      " f1_score \n",
      " 0.8749999999999999\n",
      "\n",
      " [[73  4]\n",
      " [ 2 21]]\n",
      "\n",
      " accuracy_score \n",
      " 0.94\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.9234417344173442\n",
      "\n",
      " f1_score \n",
      " 0.7906976744186047\n",
      "\n",
      " [[74  8]\n",
      " [ 1 17]]\n",
      "\n",
      " accuracy_score \n",
      " 0.91\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.9144062688366486\n",
      "\n",
      " f1_score \n",
      " 0.8260869565217391\n",
      "\n",
      " [[73  6]\n",
      " [ 2 19]]\n",
      "\n",
      " accuracy_score \n",
      " 0.92\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "roc_auc_score \n",
      "0.8235294117647058\n",
      "\n",
      " f1_score \n",
      " 0.6\n",
      "\n",
      " [[72 13]\n",
      " [ 3 12]]\n",
      "\n",
      " accuracy_score \n",
      " 0.84\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_fitting(X_train[selected_feat],X_test[selected_feat],'FS_lasso_rs_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_minmax=pd.DataFrame(X_train_scaled,columns=X_train.columns)\\ndf_minmax.head(200)'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_minmax=pd.DataFrame(X_train_scaled,columns=X_train.columns)\n",
    "df_minmax.head(200)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 26)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "training accuracy\n",
      "0.9609325771896661\n",
      "roc_auc_score \n",
      "0.9573170731707318\n",
      "\n",
      " f1_score \n",
      " 0.8372093023255813\n",
      "\n",
      " [[75  7]\n",
      " [ 0 18]]\n",
      "\n",
      " accuracy_score \n",
      " 0.93\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "training accuracy\n",
      "0.8788231302408996\n",
      "roc_auc_score \n",
      "0.8378378378378378\n",
      "\n",
      " f1_score \n",
      " 0.8064516129032258\n",
      "\n",
      " [[63  0]\n",
      " [12 25]]\n",
      "\n",
      " accuracy_score \n",
      " 0.88\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.8979857050032489\n",
      "\n",
      " f1_score \n",
      " 0.7727272727272727\n",
      "\n",
      " [[73  8]\n",
      " [ 2 17]]\n",
      "\n",
      " accuracy_score \n",
      " 0.9\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.8458498023715415\n",
      "\n",
      " f1_score \n",
      " 0.7499999999999999\n",
      "\n",
      " [[70  7]\n",
      " [ 5 18]]\n",
      "\n",
      " accuracy_score \n",
      " 0.88\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "roc_auc_score \n",
      "0.9304743339831059\n",
      "\n",
      " f1_score \n",
      " 0.8181818181818181\n",
      "\n",
      " [[74  7]\n",
      " [ 1 18]]\n",
      "\n",
      " accuracy_score \n",
      " 0.92\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_fitting(X_train_scaled,X_test_scaled,\"Scaled_direct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction \n",
    "- 2nd degree polynomialFeatures of [a, b] becomes [1, a, b, a^2, ab, b^2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 26)\n",
      "(20631, 378)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# 2nd degree polynomialFeatures of [a, b] becomes [1, a, b, a^2, ab, b^2]\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_transformed = poly.fit_transform(X_train_scaled)\n",
    "X_test_transformed = poly.fit_transform(X_test_scaled)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(X_train_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_transformed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features:\n",
      " Index(['vehicleId', 'days', 'ecoMode', 'cityMode', 'sportMode', 's1', 's2',\n",
      "       's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13',\n",
      "       's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21'],\n",
      "      dtype='object')\n",
      "Best features:\n",
      " ['1' 'x1' 'x8' 'x10' 'x11' 'x12' 'x13' 'x15' 'x16' 'x17' 'x18' 'x19' 'x21'\n",
      " 'x24' 'x25' 'x0^2' 'x0 x1' 'x0 x3' 'x0 x8' 'x0 x12' 'x0 x13' 'x0 x15'\n",
      " 'x0 x17' 'x0 x18' 'x0 x24' 'x1^2' 'x1 x2' 'x1 x6' 'x1 x7' 'x1 x10'\n",
      " 'x1 x12' 'x1 x13' 'x1 x17' 'x1 x18' 'x1 x25' 'x2 x3' 'x2 x8' 'x2 x11'\n",
      " 'x2 x13' 'x2 x16' 'x2 x18' 'x2 x21' 'x3^2' 'x3 x13' 'x3 x15' 'x3 x17'\n",
      " 'x3 x18' 'x3 x19' 'x6^2' 'x6 x8' 'x6 x12' 'x6 x15' 'x6 x17' 'x6 x19'\n",
      " 'x6 x25' 'x7 x12' 'x7 x13' 'x7 x15' 'x7 x17' 'x7 x18' 'x8^2' 'x8 x10'\n",
      " 'x8 x12' 'x8 x13' 'x8 x15' 'x8 x16' 'x8 x17' 'x8 x19' 'x8 x21' 'x10^2'\n",
      " 'x10 x11' 'x10 x12' 'x10 x13' 'x10 x15' 'x10 x16' 'x10 x17' 'x10 x18'\n",
      " 'x10 x19' 'x10 x21' 'x10 x24' 'x10 x25' 'x11^2' 'x11 x13' 'x11 x16'\n",
      " 'x11 x18' 'x11 x19' 'x11 x24' 'x11 x25' 'x12^2' 'x12 x13' 'x12 x15'\n",
      " 'x12 x16' 'x12 x17' 'x12 x18' 'x12 x19' 'x12 x21' 'x13^2' 'x13 x16'\n",
      " 'x13 x17' 'x13 x18' 'x13 x19' 'x13 x21' 'x13 x24' 'x13 x25' 'x15^2'\n",
      " 'x15 x16' 'x15 x17' 'x15 x19' 'x15 x21' 'x16^2' 'x16 x17' 'x16 x18'\n",
      " 'x16 x19' 'x16 x24' 'x16 x25' 'x17^2' 'x17 x18' 'x17 x19' 'x17 x21'\n",
      " 'x18^2' 'x18 x21' 'x18 x24' 'x18 x25' 'x19^2' 'x24^2' 'x25^2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(126,)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "select_features = SelectFromModel(logreg, threshold='mean', prefit=True)\n",
    "select_features.get_support()\n",
    "feature_names = poly.get_feature_names()\n",
    "\n",
    "print('Original features:\\n', X_train.columns)\n",
    "print('Best features:\\n', np.array(feature_names)[select_features.get_support()])\n",
    "np.array(feature_names)[select_features.get_support()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction+feature selection+scaled\n",
    "- feature selection SelectFromModel(logreg, threshold='mean', prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 126)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed[:, select_features.get_support()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy\n",
      "0.9637438805680771\n",
      "roc_auc_score \n",
      "0.9304743339831059\n",
      "\n",
      " f1_score \n",
      " 0.8181818181818181\n",
      "\n",
      " [[74  7]\n",
      " [ 1 18]]\n",
      "\n",
      " accuracy_score \n",
      " 0.92\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "training accuracy\n",
      "0.9165333721099317\n",
      "roc_auc_score \n",
      "0.8928571428571429\n",
      "\n",
      " f1_score \n",
      " 0.8727272727272728\n",
      "\n",
      " [[69  1]\n",
      " [ 6 24]]\n",
      "\n",
      " accuracy_score \n",
      " 0.93\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.90625\n",
      "\n",
      " f1_score \n",
      " 0.7999999999999999\n",
      "\n",
      " [[73  7]\n",
      " [ 2 18]]\n",
      "\n",
      " accuracy_score \n",
      " 0.91\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.8642191142191142\n",
      "\n",
      " f1_score \n",
      " 0.7659574468085107\n",
      "\n",
      " [[71  7]\n",
      " [ 4 18]]\n",
      "\n",
      " accuracy_score \n",
      " 0.89\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "roc_auc_score \n",
      "0.9144062688366486\n",
      "\n",
      " f1_score \n",
      " 0.8260869565217391\n",
      "\n",
      " [[73  6]\n",
      " [ 2 19]]\n",
      "\n",
      " accuracy_score \n",
      " 0.92\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_fitting(X_train_transformed[:, select_features.get_support()],X_test_transformed[:, select_features.get_support()],\"FE_FS_scaled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction+feature selection+scaled\n",
    "- SelectFromModel(Lasso(alpha=0.001, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Lasso(alpha=0.001, random_state=0))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sel_model = SelectFromModel(Lasso(alpha=0.001, random_state=0)) # remember to set the seed, the random state in this function\n",
    "feature_sel_model.fit(X_train_transformed,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features:\n",
      " Index(['vehicleId', 'days', 'ecoMode', 'cityMode', 'sportMode', 's1', 's2',\n",
      "       's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13',\n",
      "       's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21'],\n",
      "      dtype='object')\n",
      "Best features:\n",
      " ['x13' 'x18' 'x0 x1' 'x1 x16' 'x6 x15' 'x6 x25' 'x7 x8' 'x7 x15' 'x8^2'\n",
      " 'x8 x15' 'x8 x16' 'x8 x24' 'x8 x25' 'x11 x15' 'x12 x15' 'x15^2' 'x15 x16'\n",
      " 'x15 x19' 'x15 x25' 'x16^2' 'x18^2' 'x19 x24' 'x21^2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23,)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = poly.get_feature_names()\n",
    "\n",
    "print('Original features:\\n', X_train.columns)\n",
    "print('Best features:\\n', np.array(feature_names)[feature_sel_model.get_support()])\n",
    "np.array(feature_names)[feature_sel_model.get_support()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying 2nd degree polynomialFeatures and selecting best feature\n",
    "- but not up the mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20631, 23)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed[:, feature_sel_model.get_support()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "training accuracy\n",
      "0.9608356356938588\n",
      "roc_auc_score \n",
      "0.9518072289156627\n",
      "\n",
      " f1_score \n",
      " 0.8095238095238095\n",
      "\n",
      " [[75  8]\n",
      " [ 0 17]]\n",
      "\n",
      " accuracy_score \n",
      " 0.92\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Naive Bayes\n",
      "training accuracy\n",
      "0.9342736658426639\n",
      "roc_auc_score \n",
      "0.8768191268191268\n",
      "\n",
      " f1_score \n",
      " 0.8235294117647058\n",
      "\n",
      " [[70  4]\n",
      " [ 5 21]]\n",
      "\n",
      " accuracy_score \n",
      " 0.91\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RandomForest\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.9375\n",
      "\n",
      " f1_score \n",
      " 0.8444444444444444\n",
      "\n",
      " [[74  6]\n",
      " [ 1 19]]\n",
      "\n",
      " accuracy_score \n",
      " 0.93\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "training accuracy\n",
      "1.0\n",
      "roc_auc_score \n",
      "0.9224941724941725\n",
      "\n",
      " f1_score \n",
      " 0.8510638297872342\n",
      "\n",
      " [[73  5]\n",
      " [ 2 20]]\n",
      "\n",
      " accuracy_score \n",
      " 0.93\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "roc_auc_score \n",
      "0.90625\n",
      "\n",
      " f1_score \n",
      " 0.7999999999999999\n",
      "\n",
      " [[73  7]\n",
      " [ 2 18]]\n",
      "\n",
      " accuracy_score \n",
      " 0.91\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_fitting(X_train_transformed[:, feature_sel_model.get_support()],X_test_transformed[:, feature_sel_model.get_support()],\"FE_FS_lasso_rs0_scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- _A  -accuracy\n",
    "- _f1 -f1_score\n",
    "- _AUC- Area under the curve\n",
    "\n",
    "\n",
    "- direct                 - applying directly\n",
    "- ~low_corr              - droping low corelation var with dep var\n",
    "- FS_lasso_rs_0          - feature selection using lasso with randam state=0\n",
    "- Scaled_direct          - Scaled and directly applying\n",
    "- FE_FS_scaled           - feature engg & feature selection & Scaled\n",
    "- FE_FS_lasso_rs0_scaled - feature engg & feature selection & Scaled using lasso with randam state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>direct_A</th>\n",
       "      <th>direct_f1</th>\n",
       "      <th>direct_AUC</th>\n",
       "      <th>~low_corr_A</th>\n",
       "      <th>~low_corr_f1</th>\n",
       "      <th>~low_corr_AUC</th>\n",
       "      <th>FS_lasso_rs_0_A</th>\n",
       "      <th>FS_lasso_rs_0_f1</th>\n",
       "      <th>FS_lasso_rs_0_AUC</th>\n",
       "      <th>Scaled_direct_A</th>\n",
       "      <th>Scaled_direct_f1</th>\n",
       "      <th>Scaled_direct_AUC</th>\n",
       "      <th>FE_FS_scaled_A</th>\n",
       "      <th>FE_FS_scaled_f1</th>\n",
       "      <th>FE_FS_scaled_AUC</th>\n",
       "      <th>FE_FS_lasso_rs0_scaled_A</th>\n",
       "      <th>FE_FS_lasso_rs0_scaled_f1</th>\n",
       "      <th>FE_FS_lasso_rs0_scaled_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.909226</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.923442</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.909226</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.957317</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.930474</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.951807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.882467</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.930548</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.876819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.930474</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.923442</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.897986</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.893357</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.916371</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.914406</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.845850</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.864219</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.922494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.880936</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.930474</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.914406</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  direct_A  direct_f1  direct_AUC  ~low_corr_A  \\\n",
       "0  LogisticRegression      0.89   0.731707    0.909226         0.91   \n",
       "1         Naive Bayes      0.93   0.867925    0.896825         0.92   \n",
       "2        RandomForest      0.91   0.800000    0.906250         0.92   \n",
       "3       Decision Tree      0.91   0.808511    0.893357         0.90   \n",
       "4                 KNN      0.84   0.600000    0.823529         0.88   \n",
       "\n",
       "   ~low_corr_f1  ~low_corr_AUC  FS_lasso_rs_0_A  FS_lasso_rs_0_f1  \\\n",
       "0      0.790698       0.923442             0.89          0.731707   \n",
       "1      0.851852       0.882467             0.94          0.875000   \n",
       "2      0.818182       0.930474             0.91          0.790698   \n",
       "3      0.761905       0.916371             0.92          0.826087   \n",
       "4      0.714286       0.880936             0.84          0.600000   \n",
       "\n",
       "   FS_lasso_rs_0_AUC  Scaled_direct_A  Scaled_direct_f1  Scaled_direct_AUC  \\\n",
       "0           0.909226             0.93          0.837209           0.957317   \n",
       "1           0.930548             0.88          0.806452           0.837838   \n",
       "2           0.923442             0.90          0.772727           0.897986   \n",
       "3           0.914406             0.88          0.750000           0.845850   \n",
       "4           0.823529             0.92          0.818182           0.930474   \n",
       "\n",
       "   FE_FS_scaled_A  FE_FS_scaled_f1  FE_FS_scaled_AUC  \\\n",
       "0            0.92         0.818182          0.930474   \n",
       "1            0.93         0.872727          0.892857   \n",
       "2            0.91         0.800000          0.906250   \n",
       "3            0.89         0.765957          0.864219   \n",
       "4            0.92         0.826087          0.914406   \n",
       "\n",
       "   FE_FS_lasso_rs0_scaled_A  FE_FS_lasso_rs0_scaled_f1  \\\n",
       "0                      0.92                   0.809524   \n",
       "1                      0.91                   0.823529   \n",
       "2                      0.93                   0.844444   \n",
       "3                      0.93                   0.851064   \n",
       "4                      0.91                   0.800000   \n",
       "\n",
       "   FE_FS_lasso_rs0_scaled_AUC  \n",
       "0                    0.951807  \n",
       "1                    0.876819  \n",
       "2                    0.937500  \n",
       "3                    0.922494  \n",
       "4                    0.906250  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot grahp but is done regression model\n",
    "def gragh(df,s,e):\n",
    "    fig = plt.figure(figsize=(13,5))\n",
    "    if e > 100 or e <= 0:\n",
    "        select_engines = list(pd.unique(df.vehicleId))\n",
    "    else:\n",
    "        select_engines = np.random.choice(range(1,101), e, replace=False)\n",
    "        \n",
    "    sub1 = fig.add_subplot(221)\n",
    "    sub1.set_title('time series: ' + s +' / days(cycle)')\n",
    "    sub1.set_xlabel('days')\n",
    "    for i in select_engines:\n",
    "        df1 = df[['days', s]][df.vehicleId == i]\n",
    "        sub1.plot(df1['days'],df1[s])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for sensor in sensor_names:\\n    gragh(train,sensor,10)'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_names = ['s{}'.format(i) for i in range(1,22)]\n",
    "'''for sensor in sensor_names:\n",
    "    gragh(train,sensor,10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
